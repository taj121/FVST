%!TEX root = FVST.tex
\chapter{My Contribution}

My contributions to this project are based on the second level. These include the development of a text based syntax for the intermediate code (the code produced from the first level), a lexer and parser for this syntax and a program to verify the behaviours produced. 

The combination of lexer and parser will convert the input code, which will consist of one behaviour and one constraint, into the types defined in OCaml to represent the behaviours and constraints. A tuple of these will then be returned and passed into the behaviour checker where the rules from \ref{rules2} will be applied to verify that the program will in fact communicate as expected. 

One limitation of the checker that is worth noting is that it will not infer types and so these must be explicitly stated in the input code. 

\section{Text Based Syntax} \label{text}

\subsection {Design} 
The syntax given in the paper can be seen in fig. \ref{syntaxTypes}. To develop an easy to parse version of this syntax Greek letter have been removed, keywords or individual letters have been chosen to replace them. The substitutions made can be seen in the given syntax for the input code in section \ref{gram} and the table below detailing the syntax of the substitutions where their syntax is not directly stated in the grammars given.

\begin{tabular}{l l c }
Type Variables & $\alpha$ & [T][A-Z a-z 1-9]+ \\
Behaviour Variables &$\beta$ & [B][A-Z a-z 1-9]+ \\
Session Variables & $\psi$ & [S][A-Z a-z 1-9]+ \\
Region Variables & $\rho$ & [R][A-Z a-z 1-9]+ \\
Labels & l & \$[A-Z a-z 1-9]+\$ \\
\end{tabular}

\subsection{Challenges}
The design of the text based syntax was relatively simple and posed few challenges. 

\section{Lexer and parser}

\subsection{Lexer}
The lexer was designed using OCamlLex which is based on Lex, a lexical analyser generator. This takes a set of regular expressions and corresponding semantic actions. In this case the regular expressions are the keywords, labels, variables, etc. and the associated actions are either tokens that link to the parser or, in the case of the opening \$ for labels, calls a second lexing function to deal with labels. 

\subsection{Parser}
The parser was implemented using Menhir. This is a parser generator that is closely related to OCamlyacc which in turn is based on yacc. These generate LR(1) parsers, meaning that the input is parsed from the bottom up and that there is one character look ahead. 

In the parser first the tokens are declared for every relevant grouping of input. Then the structure of the accepted input and the code to be invoked when that input is encountered are specified. The structure of the input can be seen in \ref{gram}.

\subsection{Challenges}
The main challenge encountered when designing the lexer and the parser was learning the correct usage of OCamlLex and Menhir. Having never used anything like this before from scratch these took some time to get used to. 

Another challenge encountered with the lexer was parsing the end of file. An unknown issues causes the lexer to state that it finds a syntax error at the final character of the input file. While this is misleading to the user and not entirely correct it does not effect the behaviour of the behaviour checker and so has been ignored. 

Finally initially there were some errors with shift/reduce conflicts in the parser. These were caused by not initially including operator precedence for `;' and `,' meaning that the execution order of sequencing of behaviours and constraints was unclear. As well as this there were not initially brackets in the $rec <behaviourVariable> (<behaviour>)$ rule which also caused an issue. This was that it was unclear in the case $rec <behaviourVariable> <behaviour> ; <behaviour>  $ if the recursive behaviour was in the sequence or if the sequence was the behaviour associated with the recursion. 

\subsection{Grammar} \label{gram}

The grammar was designed with usability in mind. The main entry point for the grammar is shown first. This states that the parser will read a behaviour followed by a constraint followed by the end of file. In all cases in this description of the grammar the `Strings' are the input as it appears in the file and anything inside $< >$ is either another type from the grammar or a variable the syntax of which is given in \ref{text}.

\begin{grammar}

<parse_behaviour> ::= <behaviour> <constraint> EOF

\end{grammar}

\subsubsection{Behaviour}

The behaviour type in the grammar consists of multiple options. The final option is interesting. This represents the offer of external choice and we can see that it contains a list. This will call to a sub rule that states that this list consists of comma separated values of another subtype (opt_feild). 

\begin{grammar}
<behaviour> ::= <behaviourVariable>
\alt `tau'
\alt <behaviour> `;' <behaviour>
\alt `chc' (<behaviour>,<behaviour>)
\alt `rec' <behaviourVariable> (<behaviour>)
\alt `spn' (<behaviour>)
\alt `psh' (<lable>,<sessionType>)
\alt <region> `!' <behaviourVariable>
\alt <region> `?' <behaviourVariable>
\alt <region> `!' <region>
\alt <region> `?' <lable>
\alt <region> `!' <lable>
\alt <region> `?' option[<oplist>]

<oplist> ::= `(' <lable> `;' <behavioiur> `)' <opt_feild>

<opt_feild> ::= `,' `(' <lable> `;' <behavioiur> `)'
\alt $\epsilon$

\end{grammar}

\subsubsection{Constraints}

Constraints are similar to behaviours but also use the sub-grammar for bTypes, regions and session types which are given below. 

\begin{grammar}

<constr> ::= <bType> `\textless' <bType>
\alt <behaviour> `\textless' <behaviour>
\alt <region> `\texttildelow' <regionVar>
\alt <channel> `\texttildelow' <sessionType>
\alt <channelEnd> `\texttildelow' <sessionType>
\alt <contr> `,' <constr>
\alt $\epsilon$

\end{grammar}

\subsubsection{Types}

The implementation of types is relatively simple. They can be any of the forms listed below and use the sub-grammar for regions. 
\begin{grammar}

<bType> ::= `unit'
\alt `bool '
\alt `int'
\alt `pair' `(' <bType> `;' <bType> `)'
\alt `funct' <bType> `->' <bType> `-' <behaviourVariable>
\alt `ses' <region>
\alt <TVar>

\end{grammar}

\subsubsection {Region Variables}

Regions are very simple and either consist of a region variable or a label (see \ref{text} for syntax). 

\begin{grammar}

<regionVar> ::= <lable>
\alt <region>

\end{grammar}

\subsubsection{Session Types}

\begin{grammar}

<sessionType> ::= `end'
\alt `!' <bType> <sessionType>
\alt `?' <bType> <sessionType>
\alt `!' <sessionType> <sessionType>
\alt `?' <sessionType> <sessionType>
\alt `(+)' `['<sesOpL>`]' `('<lable> `;' <sessionType>`)'
\alt `+' `['<sesOpL>`]' `['<sesOpL>`]'
\alt <SVar>

<sesOpL> ::= `('<lable> `;' <sessionType>`)' <ses_opt_field>

<ses_opt_field> := `,' `('<lable> `;' <sessionType>`)'
\alt $\epsilon$

\end{grammar}

\section{OCaml Types}

In order for the parser to have the correct types for dealing with behaviours and constraints these first needed to exist. This involved creating new types in OCaml for each of Behaviours, Constraints, Types, Regions and Session types. These main types are built up of subtypes, strings and, in the case of `Tau' and `End' nothing. 

These types take the following form: 

\lstinputlisting[language=Caml, firstline=42, lastline=68]{../../Behaviour.ml}

you can clearly see how RecChoice, the external choice type is made up of the subtype recC which in turn consists of a string and list of string, behaviour tuples. 

The other types are implemented in a similar way. 

As well as implementing the types each type also has a to_string function. This is to allow for the re-printing of the input code as part of the output. 

\subsection{Challenges}

Again the main challenges with implementing this part of the project was the new language. While OCaml has excellent documentation it was not easy to find examples or tutorials to help with implementing such an interlinked system of types. 

\section{Behaviour Checker}

The behaviour checker is implementing the rules from fig. \ref{rules2}. The first step towards implementing these was to store the relevant information in an easily accessible form. In this case that meant storing the relevant constraints. We then had to look at the behaviour read in from the file and check it in relation to these constraints. 

\subsection{Storing the Constraints}

The constraints that are relevant to the Behaviour Checker are the region constraints, the behaviour constraints and the type constraints. Each is stored in a slightly different way to account for the fact that the format and usage of each of the constraint types is different. Other constraints are not stored. 

\subsubsection{Behaviour Constraints}

These constraints are of the form $$b \subseteq \beta$$ where b is a behaviour and $\beta$ is a behaviour variable. These constraints are used in the Beta and Rec rules. In the Beta rule ($\bigtriangleup \models \beta \rightarrow c \bigtriangleup \models b$ if $C \vdash b \subseteq \beta$) the constraints are used to replace the behaviour variable beta with each behaviour associated with it and to check that each of these are valid. 

In the recursion (Rec) rule the behaviour constraints are used where there are any constraints of which the left hand side matches the current recursion behaviour. In this case the left hand side of that rule is replaced with Tau. 

The decision was made to store the behaviour constraints as a hash table. The key is the right hand side of the constraint $\beta$ and the value is the left hand side (the behaviour associated with beta). In this was in the case of either rule we can search quickly and find all values associated with the key and have them returned as a list. We can then either replace $\beta$ with each value from the list in turn (Beta Rule) or we can search the list to find and replace any instances of the current recursion behaviour. 

\subsubsection{Type Constraints}

Type constraints are of the form $$T_1 <: T_2$$ and are used in the Out Rule. They are used according to semantics that state that if the constraint exists then $T_1$ is a functional subtype of $T_2$. If both $T_1$ and $T_2$ are pairs then if the first type of the first pair is a subtype of the first type of the second pair and the same is true of the second types of both pairs then the first pair is a subtype of the second. It is a similar case for function. 

If both types are of the form $Ses^{\rho}$ then if there exists a region constraint linking the $\rho$'s  they are functional subtypes.

Type constraints are stored as a hash table with the right hand type as the key and the left hand type as the value. Since type constraints are also transitive this means that when checking these constraints we first search for the right hand side of the constraint we wish to check. Then we get the list of associated subtypes for that type and recursively search for these as keys until either we run out of types to search for or we find the type we are looking for. 

Since type constraints are also reflexive we always check if the two types are equal first.

\subsubsection{Region Constraints}

Region constraints take the form of either $$\rho \sim \rho'$$ or $$\rho \sim l$$ and are used in the rules: Out, In, Del, Res, ICh and ECh. They are used in the same way for each of the rules which is simply to check if there is a link between a region and a label. The complication arises from the fact that regions can be chained and then linked to a label. For example $\rho_1 \sim \rho_2$, $\rho_2 \sim \rho_3$ and $\rho_3 \sim l1$ tells us that $\rho_1,\rho_2$ and $\rho_3$ are all linked to $l1$.

Due to this region constraints are stored as a list of tuples which each consist of a label and a hash table with region variables as keys and unit as values. In this way when looking up a particular label and region we can simply search for the label in the list and then check the hash table. 

Storing the constraints in this way in a single pass through the constraint list was challenging. It is achieved by first creating a new tuple consisting of either a label or a None and a hash table with either one or two values. All other elements from the list that match either of the two values associated with the new constraint are then found and removed from the list. The are merge together with the new element to form a single list element and added back to the new list which is returned. 

\subsection{Behaviour Checker Function}

The behaviour checker verifies that the input program will in fact communicate correctly. It takes an input of the behaviours produced from the first level (\ref{level1}) and the constraints stored in the method described above. The behaviours are then checked against the rules from fig. \ref{rules2} and the appropriate actions taken. 

The parameters to the function are a set of constraints and a list of behaviour tuples of the form $(behaviour, stack, stack_labels, continuation)$. The stack represents the one described in the rules and the stack labels is used to ensure that each label is only ever pushed to the stack once. The continuation is used to keep track of any behaviours that need to be dealt with once the current behaviour is finished with. 

The initial function called is a wrapper function that calls to a check step function with the first tuple from the list. The function is set up this way so that if the need arose to read in more than one behaviour from a file it would be supported. 

The check_step function then takes the current stack and checks to see if the top frame contains the `End' session type (i.e. it applies the end rule) if it does it removes this frame and then it continues to check the to see which of the rest of the rules apply. 

The behaviour of the Beta rule has already been briefly described. A diagram detailing the behaviour of the Sequence can be seen in fig. \ref{seq}. As you can see from this the continuation is used to store the second behaviour in the sequence while the first one is been dealt with. 

The other rules are applied in a similar way. 

\begin{figure}
\includegraphics[scale=0.5]{treeDig2.png}
\caption{Application of Sequence Rule}
\label{seq}
\end{figure}

\subsection{Results}
The behaviour checker will output for us the results of the check. In the case of the check failing it will also inform us of the rule on which the check failed but not the location in the source code.

If the check is successful we have shown that the input code follows the correct protocol for the communication channel. We have also shown partial lock freedom due to the well stackness of the program. 

\subsection{Challenges}
The main challenges encountered in this implementation of the checker was, again, the new language. However this was overcome more quickly when developing this section of the project.

Other challenges encountered included dealing with the different implementations of stack and hash tables in the standard library and the core_kernal library. The stacks in the core_kernel library included functions that made for a much nicer implementation but the hash tables were missing the functionality to return lists of all bindings to a key. This was overcome when I realised it was possible to rename the hash table module from the standard library before importing the core_kernel library and so avoid the shadowing of the binding. 

The implementation of the region constraint storage was also took quiet some time since it is rather complicated code and pushed my knowledge of the OCaml language to it boundaries. 


